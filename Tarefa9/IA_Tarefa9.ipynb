{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Passo 1: Importando Bibliotecas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import PIL\n",
        "import scipy\n",
        "from scipy import ndimage"
      ],
      "metadata": {
        "id": "5RnbZgE3cN1W"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sugrnkkOb0Pm",
        "outputId": "6ef11fb8-23f5-4030-e208-3b1b3ae59cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Passo 2: Montando Pasta do Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 3: Função para carregar o dataset\n",
        "def load_dataset():\n",
        "    train = h5py.File('/content/drive/My Drive/datasets/train_catvnoncat.h5', \"r\")\n",
        "    # X_train =    (Obter de train com np.array, escolhendo a coluna certa de train)\n",
        "    # y_train =    (Obter de train com np.array, escolhendo a coluna certa de train)\n",
        "\n",
        "    test = h5py.File('/content/drive/My Drive/datasets/test_catvnoncat.h5', \"r\")\n",
        "    # X_test =      (Obter de test com np.array, escolhendo a coluna certa de test)\n",
        "    # y_test =      (Obter de test com np.array, escolhendo a coluna certa de test)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "-gAskgRZctui"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 5: Carrega os dados (cat/non-cat)\n",
        "X_train, y_train, X_test, y_test = load_dataset()"
      ],
      "metadata": {
        "id": "U94WxEiccykk"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 6: Imprimindo o shape atual do X_train e X_teste\n",
        "print(\"Shape do X_treino: {}\".format(X_train.shape))\n",
        "print(\"Shape do y_treino: {}\".format(y_train.shape))\n",
        "print(\"Shape do X_teste: {}\".format(X_test.shape))\n",
        "print(\"Shape do y_teste: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwJ9NRtax64o",
        "outputId": "f45ad74c-f07e-4c10-d92d-8891df45236c"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape do X_treino: (209, 64, 64, 3)\n",
            "Shape do y_treino: (209,)\n",
            "Shape do X_teste: (50, 64, 64, 3)\n",
            "Shape do y_teste: (50,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 7: Aplicar um achatamento das matrizes para estas fiquem como:\n",
        "\n",
        "# Shape do X_treino: (209, 12288)\n",
        "# Shape do y_treino: (209,)\n",
        "# Shape do X_teste: (50, 12288)\n",
        "# Shape do y_teste: (50,)"
      ],
      "metadata": {
        "id": "6ZBEoCIdGAcs"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 8: Aplicar uma padronização dividindo X_train e X_test por /255.0"
      ],
      "metadata": {
        "id": "_EgW1w32GbjU"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 9: Organizar os dados para entrada no sklearn\n",
        "# Os datasets de treinamento devem ser inseridos como (209, 12288) e (50, 12288)\n",
        "# Este é o formato pedido pelo sklearn. Outros frameworks como keras e tensorflow isso não necessário"
      ],
      "metadata": {
        "id": "RhwLosq4IpKU"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 10: Criar um modelo de regressao logistica"
      ],
      "metadata": {
        "id": "Ape07zUyGkbo"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 11: Treinar o modelo de regressão logística"
      ],
      "metadata": {
        "id": "SyVBV3PdJLI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 12: Realizar predições"
      ],
      "metadata": {
        "id": "l_ssbykdJcDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 13: Realizar análise de métricas de classificação (Matriz de Confusão, Acurácia, etc.)"
      ],
      "metadata": {
        "id": "bfIzLn13JflM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}